{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MetaBeeAI PDF to text pipeline tutorial\n",
    "\n",
    "Walk through the steps of the MetaBeeAI PDF to text pipeline.\n",
    "\n",
    "1. Split the PDF into overlapping 2-page PDFs\n",
    "2. Process the PDFs using Vision Agentic Document Analysis\n",
    "\n",
    "Starting with a directory of PDFs, each within a numbered 3-digit subfolder, e.g.:\n",
    "\n",
    "```\n",
    "data/papers/\n",
    "├── 001/\n",
    "│   ├── main.pdf\n",
    "└── 002/\n",
    "    ├── main.pdf\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: create virtual environment\n",
    "\n",
    "```\n",
    "python -m venv metabeeai_pdf_to_text\n",
    "source metabeeai_pdf_to_text/bin/activate\n",
    "```\n",
    "\n",
    "Step 2: install dependencies\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Step 3: create .env file with your API keys\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=your_openai_api_key\n",
    "LANDING_AI_API_KEY=your_landing_ai_api_key\n",
    "ANTHROPIC_API_KEY=your_anthropic_api_key\n",
    "```\n",
    "\n",
    "Step 4: install the package\n",
    "\n",
    "```\n",
    "pip install -e . # in development mode\n",
    "```\n",
    "\n",
    "or:\n",
    "\n",
    "```\n",
    "pip install .\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split the PDF into overlapping 2-page PDFs using `split_pdf.py`\n",
    "\n",
    "The script will:\n",
    "- Look for subfolders in the specified directory\n",
    "- For each subfolder, look for a PDF named {subfolder}_main.pdf\n",
    "- Create a \"pages\" subdirectory if it doesn't exist\n",
    "- Split the PDF into overlapping 2-page PDFs named main_p01-02.pdf, main_p02-03.pdf, etc.\n",
    "\n",
    "Note that this script requires exactly one argument - the directory containing your paper subfolders. \n",
    "\n",
    "The directory should have this structure:\n",
    "\n",
    "papers_directory/\n",
    "    001/\n",
    "        001_main.pdf\n",
    "    002/\n",
    "        002_main.pdf\n",
    "    ...\n",
    "\n",
    "Basic usage (requires directory argument)\n",
    "```\n",
    "python -m metabeeai_pdf.split_pdf data/papers\n",
    "```\n",
    "\n",
    "Or with full path\n",
    "```\n",
    "python -m metabeeai-pdf.split_pdf /path/to/papers/directory\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metabeeai-pdf.split_pdf import split_pdfs\n",
    "\n",
    "# Basic usage\n",
    "split_pdfs(\"data/papers\")\n",
    "\n",
    "# Or with full path\n",
    "split_pdfs(\"/path/to/papers/directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Vision Agentic Document Analysis\n",
    "\n",
    "Vision Agentic Document Analysis uses computer vision to extract text from the PDFs. It outputs a JSON file for each PDF, with chunks of text (or image descriptions) labeled with unique IDs and chunk types (e.g., \"text\", \"figure\", \"header\", etc.).\n",
    "\n",
    "Parameters:\n",
    "--dir / papers_dir: Directory containing paper folders (default: \"data/papers\")\n",
    "--start / start_folder: Optional folder number to start processing from (e.g., \"059\")\n",
    "\n",
    "The script will:\n",
    "- Look for PDF files in the \"pages\" subdirectory of each paper folder\n",
    "- Process each PDF using the Landing AI Vision Agentic Document Analysis API\n",
    "- Save the results as JSON files alongside the PDFs\n",
    "- Create a timestamped log file in the papers directory\n",
    "\n",
    "Note: Make sure you have:\n",
    "- Set up your .env file with a LANDING_AI_API_KEY as well as OPENAI_API_KEY and ANTHROPIC_API_KEY\n",
    "\n",
    "The required directory structure:\n",
    "papers_directory/\n",
    "    001/\n",
    "        pages/\n",
    "            main_p01-02.pdf\n",
    "            main_p02-03.pdf\n",
    "            ...\n",
    "    002/\n",
    "        pages/\n",
    "            ...\n",
    "\n",
    "Basic usage (uses default data/papers directory)\n",
    "```\n",
    "python -m metabeeai-pdf.va_process_papers\n",
    "```\n",
    "With specific directory\n",
    "```\n",
    "python -m metabeeai-pdf.va_process_papers --dir data/papers\n",
    "```\n",
    "Start from a specific folder number\n",
    "```\n",
    "python -m metabeeai_pdf.va_process_papers --dir data/papers --start 059\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metabeeai-pdf.va_process_papers import process_papers\n",
    "\n",
    "# Basic usage (uses default \"../data/papers\" directory)\n",
    "process_papers()\n",
    "\n",
    "# With specific directory\n",
    "process_papers(papers_dir=\"data/papers\")\n",
    "\n",
    "# Start from a specific folder number\n",
    "process_papers(papers_dir=\"data/papers\", start_folder=\"059\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick check of chunk IDs to make sure they are unique\n",
    "\n",
    "The script will:\n",
    "- Check all JSON files (except merged.json) in each pages/ subfolder\n",
    "- Look for duplicate chunk_ids\n",
    "- Print any duplicates found\n",
    "- Save a detailed log file with results to either:\n",
    "    - data/logs/chunk_id_check_[timestamp].json (for relative paths)\n",
    "    - [papers_dir]/logs/chunk_id_check_[timestamp].json (for absolute paths)\n",
    "The log file will contain a summary of how many subfolders were checked and how many had duplicates, along with detailed information about any duplicates found.\n",
    "\n",
    "Basic usage (uses default data/papers directory)\n",
    "```\n",
    "python -m metabeeai-pdf.unique_chunk_id\n",
    "```\n",
    "\n",
    "Specify a custom directory\n",
    "``` \n",
    "python -m metabeeai-pdf.unique_chunk_id --dir path/to/papers\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metabeeai-pdf.unique_chunk_id import check_chunk_ids_in_pages_dir\n",
    "\n",
    "# Basic usage (uses default data/papers directory)\n",
    "check_chunk_ids_in_pages_dir()\n",
    "\n",
    "# Specify a custom directory\n",
    "check_chunk_ids_in_pages_dir(papers_dir=\"path/to/papers\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
